version: "3.8"

services:
  servicio-chat:
    image: llm_connector        # ya la tienes construida localmente
    ports:
      - "8000:8000"
    deploy:
      replicas: 1               # puedes subir a 2–3 si quieres
      restart_policy:
        condition: any
    environment:
      # Si tu servicio de chat usa Gemini, pasa la key como variable
      # GEMINI_API_KEY: ${GEMINI_API_KEY}
      # o la que uses internamente:
      # gemini_api_key: ${GEMINI_API_KEY}
      # (ajústalo a cómo lo lees en tu código)
      - GEMINI_API_KEY=${GEMINI_API_KEY}

  servicio-cnn:
    image: cnn_image
    ports:
      - "8002:8002"
    deploy:
      replicas: 1
      restart_policy:
        condition: any

  servicio-linear:
    image: ml_model
    ports:
      - "8003:8003"
    deploy:
      replicas: 1
      restart_policy:
        condition: any

  gradio-gui:
    image: gradio-gui
    ports:
      - "7860:7860"
    deploy:
      replicas: 1
      restart_policy:
        condition: any
    environment:
      # Ojo: dentro de Swarm los servicios se ven por su NOMBRE
      - url=http://servicio-chat:8000/chat
      - model_url=http://servicio-linear:8003/model/linear/prediction
      - CNN_URL=http://servicio-cnn:8002/api/cnn/classify
